#!/usr/bin/env python3
"""
Servidor ultra-r√°pido con cache agresivo para compensar latencia de BD
"""
import json
import time
import hashlib
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
import mysql.connector.pooling
import uvicorn
import asyncio
from concurrent.futures import ThreadPoolExecutor

app = FastAPI(title="Gastro Fast Server")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configuraci√≥n MySQL
MYSQL_CONFIG = {
    'host': 'mysql-aiven-arenazl.e.aivencloud.com',
    'port': 23108,
    'user': 'avnadmin',
    'password': 'AVNS_Fqe0qsChCHnqSnVsvoi',
    'database': 'gastro'
}

# Pool de conexiones
connection_pool = mysql.connector.pooling.MySQLConnectionPool(
    pool_name="gastro_fast_pool",
    pool_size=5,
    **MYSQL_CONFIG,
    ssl_disabled=False,
    autocommit=True
)

# Executor para queries paralelos
executor = ThreadPoolExecutor(max_workers=10)

# ============================================================
# SISTEMA DE CACHE INTELIGENTE
# ============================================================

class SmartCache:
    """
    Cache inteligente con:
    - Precarga de datos frecuentes
    - Invalidaci√≥n selectiva
    - TTL diferenciado por tipo de dato
    """
    
    def __init__(self):
        self.cache = {}
        self.ttl_config = {
            'categories': 300,      # 5 minutos - cambian poco
            'products': 120,        # 2 minutos - pueden cambiar stock
            'tables': 30,           # 30 segundos - estado cambia frecuente
            'subcategories': 300,   # 5 minutos
            'customers': 180,       # 3 minutos
        }
    
    def get(self, key: str) -> Optional[Any]:
        if key in self.cache:
            data, timestamp, ttl = self.cache[key]
            if time.time() - timestamp < ttl:
                return data
            else:
                del self.cache[key]
        return None
    
    def set(self, key: str, data: Any, cache_type: str = 'default'):
        ttl = self.ttl_config.get(cache_type, 60)
        self.cache[key] = (data, time.time(), ttl)
    
    def invalidate_pattern(self, pattern: str):
        """Invalidar todas las keys que coincidan con el patr√≥n"""
        keys_to_delete = [k for k in self.cache.keys() if pattern in k]
        for key in keys_to_delete:
            del self.cache[key]
    
    def preload(self):
        """Precargar datos m√°s usados al iniciar"""
        print("üì¶ Precargando cache...")
        
        # Precargar categor√≠as
        with get_db_connection() as conn:
            cursor = conn.cursor(dictionary=True)
            
            # Categor√≠as
            cursor.execute("SELECT * FROM categories WHERE is_active = TRUE")
            categories = cursor.fetchall()
            self.set('categories_all', categories, 'categories')
            
            # Subcategor√≠as
            cursor.execute("SELECT * FROM subcategories")
            subcategories = cursor.fetchall()
            for cat in categories:
                cat_subs = [s for s in subcategories if s['category_id'] == cat['id']]
                self.set(f'subcategories_{cat["id"]}', cat_subs, 'subcategories')
            
            # Productos por categor√≠a (los m√°s pedidos)
            for cat in categories[:5]:  # Solo las 5 primeras categor√≠as
                cursor.execute("""
                    SELECT p.*, c.name as category_name, s.name as subcategory_name
                    FROM products p
                    LEFT JOIN categories c ON p.category_id = c.id
                    LEFT JOIN subcategories s ON p.subcategory_id = s.id
                    WHERE p.category_id = %s AND p.available = TRUE
                """, (cat['id'],))
                products = cursor.fetchall()
                self.set(f'products_cat_{cat["id"]}', products, 'products')
            
            cursor.close()
        
        print(f"‚úÖ Cache precargado con {len(self.cache)} elementos")

# Instancia global del cache
smart_cache = SmartCache()

# ============================================================
# FUNCIONES DE BD OPTIMIZADAS
# ============================================================

def get_db_connection():
    """Obtener conexi√≥n del pool"""
    return connection_pool.get_connection()

async def execute_query_async(query: str, params: tuple = None) -> List[Dict]:
    """Ejecutar query en thread separado para no bloquear"""
    loop = asyncio.get_event_loop()
    
    def _execute():
        with get_db_connection() as conn:
            cursor = conn.cursor(dictionary=True)
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            result = cursor.fetchall()
            cursor.close()
            return result
    
    return await loop.run_in_executor(executor, _execute)

# ============================================================
# ENDPOINTS OPTIMIZADOS
# ============================================================

@app.on_event("startup")
async def startup_event():
    """Precargar cache al iniciar"""
    smart_cache.preload()

@app.get("/health")
async def health():
    return {
        "status": "operational",
        "server": "fast_cached_server",
        "cache_items": len(smart_cache.cache),
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/categories")
async def get_categories():
    """Obtener categor√≠as (casi siempre desde cache)"""
    # Intentar cache primero
    cached = smart_cache.get('categories_all')
    if cached:
        return {"categories": cached, "from_cache": True}
    
    # Si no hay cache, buscar y cachear
    categories = await execute_query_async(
        "SELECT * FROM categories WHERE is_active = TRUE ORDER BY name"
    )
    smart_cache.set('categories_all', categories, 'categories')
    return {"categories": categories, "from_cache": False}

@app.get("/api/products")
async def get_products(
    category_id: Optional[int] = None,
    subcategory_id: Optional[int] = None,
    search: Optional[str] = None
):
    """Obtener productos con cache inteligente"""
    
    # Generar cache key √∫nica
    cache_key = f"products_cat_{category_id}_sub_{subcategory_id}_search_{search}"
    
    # Intentar cache
    cached = smart_cache.get(cache_key)
    if cached:
        return {"products": cached, "from_cache": True}
    
    # Construir query
    query = """
        SELECT p.*, c.name as category_name, s.name as subcategory_name
        FROM products p
        LEFT JOIN categories c ON p.category_id = c.id
        LEFT JOIN subcategories s ON p.subcategory_id = s.id
        WHERE p.available = TRUE
    """
    
    params = []
    if category_id:
        query += " AND p.category_id = %s"
        params.append(category_id)
    
    if subcategory_id:
        query += " AND p.subcategory_id = %s"
        params.append(subcategory_id)
    
    if search:
        query += " AND p.name LIKE %s"
        params.append(f"%{search}%")
    
    query += " ORDER BY p.name"
    
    # Ejecutar query
    products = await execute_query_async(query, tuple(params) if params else None)
    
    # Cachear resultado
    smart_cache.set(cache_key, products, 'products')
    
    return {"products": products, "from_cache": False}

@app.get("/api/subcategories")
async def get_subcategories(category_id: int):
    """Obtener subcategor√≠as de una categor√≠a"""
    cache_key = f"subcategories_{category_id}"
    
    cached = smart_cache.get(cache_key)
    if cached:
        return {"subcategories": cached, "from_cache": True}
    
    subcategories = await execute_query_async(
        "SELECT * FROM subcategories WHERE category_id = %s ORDER BY name",
        (category_id,)
    )
    
    smart_cache.set(cache_key, subcategories, 'subcategories')
    return {"subcategories": subcategories, "from_cache": False}

@app.get("/api/tables")
async def get_tables():
    """Obtener mesas (cache corto por cambios frecuentes)"""
    cache_key = "tables_all"
    
    cached = smart_cache.get(cache_key)
    if cached:
        return {"tables": cached, "from_cache": True}
    
    tables = await execute_query_async(
        "SELECT * FROM tables ORDER BY table_number"
    )
    
    smart_cache.set(cache_key, tables, 'tables')
    return {"tables": tables, "from_cache": False}

@app.post("/api/auth/login")
async def login(credentials: dict):
    """Login r√°pido con cache de usuarios"""
    email = credentials.get('email')
    password = credentials.get('password')
    
    # Hash password
    password_hash = hashlib.sha256(password.encode()).hexdigest()
    
    # Cache key para el usuario
    cache_key = f"user_{email}"
    
    # Intentar cache
    cached_user = smart_cache.get(cache_key)
    if cached_user and cached_user['password'] == password_hash:
        return {
            "access_token": f"token_{email}_{int(time.time())}",
            "user": {
                "id": cached_user['id'],
                "email": cached_user['email'],
                "name": cached_user['name'],
                "role": cached_user['role']
            },
            "from_cache": True
        }
    
    # Buscar en BD
    users = await execute_query_async(
        "SELECT * FROM users WHERE email = %s",
        (email,)
    )
    
    if not users:
        # Usuario no existe, crear uno por defecto si es admin
        if email == "admin@restaurant.com" and password == "admin":
            return {
                "access_token": f"token_admin_{int(time.time())}",
                "user": {
                    "id": 1,
                    "email": "admin@restaurant.com",
                    "name": "Admin",
                    "role": "admin"
                }
            }
        raise HTTPException(status_code=401, detail="Invalid credentials")
    
    user = users[0]
    user['password'] = password_hash  # Para cache
    smart_cache.set(cache_key, user, 'customers')
    
    return {
        "access_token": f"token_{email}_{int(time.time())}",
        "user": {
            "id": user['id'],
            "email": user['email'],
            "name": user.get('name', 'User'),
            "role": user.get('role', 'admin')
        },
        "from_cache": False
    }

@app.get("/api/cache/stats")
async def cache_stats():
    """Estad√≠sticas del cache para monitoreo"""
    stats = {
        "total_items": len(smart_cache.cache),
        "items_by_type": {},
        "memory_estimate": 0
    }
    
    for key in smart_cache.cache:
        # Categorizar por tipo
        if 'categories' in key:
            type_name = 'categories'
        elif 'products' in key:
            type_name = 'products'
        elif 'tables' in key:
            type_name = 'tables'
        else:
            type_name = 'other'
        
        stats['items_by_type'][type_name] = stats['items_by_type'].get(type_name, 0) + 1
    
    return stats

@app.post("/api/cache/invalidate")
async def invalidate_cache(pattern: Optional[str] = None):
    """Invalidar cache manualmente"""
    if pattern:
        smart_cache.invalidate_pattern(pattern)
        return {"message": f"Cache invalidado para patr√≥n: {pattern}"}
    else:
        smart_cache.cache.clear()
        return {"message": "Todo el cache ha sido limpiado"}

if __name__ == "__main__":
    print("=" * 60)
    print("üöÄ SERVIDOR ULTRA-R√ÅPIDO CON CACHE INTELIGENTE")
    print("=" * 60)
    print("üìç Puerto: 8001")
    print("üîó URL: http://0.0.0.0:8001")
    print("üíæ Cache: Precargado con datos frecuentes")
    print("‚ö° Performance: Respuestas < 100ms con cache")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=8001)